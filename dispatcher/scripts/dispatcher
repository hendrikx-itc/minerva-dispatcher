#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Minerva Dispatcher command line script.

Dispatcher/harvest job sources look like this:

{
    "uri": "/data",
    "recursive": true,
    "match_pattern": ".*",
    "job_config": {}
}

"""
__docformat__ = "restructuredtext en"

__copyright__ = """
Copyright (C) 2008, 2015 Hendrikx-ITC B.V.

Distributed under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3, or (at your option) any later
version.  The full license is in the file COPYING, distributed as part of
this software.
"""
import os
import argparse
import logging.handlers
import signal
from contextlib import closing
from functools import partial
import traceback
import threading
from operator import not_

import psycopg2.extensions

from minerva.util import compose, no_op, after, retry_while
from minerva.instance import connect

from minerva_dispatcher.version import __version__ as version
from minerva_dispatcher import JobCollector, get_job_sources

SIGNAL_MAP = {
    signal.SIGKILL: "SIGKILL",
    signal.SIGTERM: "SIGTERM",
    signal.SIGINT: "SIGINT",
    signal.SIGUSR1: "SIGUSR1"
}

package_name = "minerva_dispatcher"
script_name = os.path.basename(__file__)
config_file = "{}.conf".format(script_name)


def main():
    """Script entry point."""
    parser = argparse.ArgumentParser(
        description="watch job sources for new files/jobs")

    parser.add_argument(
        "--version", action="version", version='%(prog)s {}'.format(version),
        help="display version information and exit")

    stop_event = threading.Event()

    stop = after(stop_event.set, log_signal)

    signal.signal(signal.SIGTERM, stop)
    signal.signal(signal.SIGINT, stop)

    def connect_retry():
        while not stop_event.is_set():
            try:
                return connect()
            except Exception as exc:
                logging.error(exc)
                stop_event.wait(1.0)

    with closing(connect_retry()) as conn:
        with closing(conn.cursor()) as cursor:
            job_sources = get_job_sources(cursor)

        conn.commit()

        job_collector = JobCollector(job_sources, stop_event)
        job_collector.start()

        logging.info("started with pid {0:d}".format(os.getpid()))

        for job in job_collector.iter_jobs():
            store_job(conn, stop_event, job)

        logging.info("loop terminated")

        job_collector.stop()
        job_collector.join()
        logging.info("collector stopped")

        conn.commit()

        logging.info("stopped")


def on_connection(conn):
    def f(cmd):
        with closing(conn.cursor()) as cursor:
            cmd(cursor)

    return f


def store_job(conn, stop_event, job):
    try:
        resilient_db_exec(
            action=partial(on_connection(conn), job),
            stop_event=stop_event
        )
    except:
        logging.error(traceback.format_exc())
        conn.rollback()
    else:
        conn.commit()
        logging.info("enqueued {}".format(job.description["uri"]))


# In case of a database shutdown, we first get an InterfaceError and the
# next time an OperationalError
EXCEPTION_HANDLER_MAP = {
    psycopg2.InterfaceError: no_op,
    psycopg2.OperationalError: no_op
}


def resilient_db_exec(action, stop_event):
    condition = compose(not_, stop_event.is_set)

    retry_while(action, EXCEPTION_HANDLER_MAP, condition)


def log_signal(signum, _frame):
    logging.info("{0!s} signal received".format(
        SIGNAL_MAP.get(signum, signum)))


if __name__ == "__main__":
    main()
