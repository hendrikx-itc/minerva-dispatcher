#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Minerva Dispatcher command line script

Dispatcher/harvest job sources look like this:

{
    "uri": "/data",
    "recursive": true,
    "match_pattern": ".*",
    "job_config": {}
}
"""
__docformat__ = "restructuredtext en"

__copyright__ = """
Copyright (C) 2008, 2013 Hendrikx-ITC B.V.

Distributed under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3, or (at your option) any later
version.  The full license is in the file COPYING, distributed as part of
this software.
"""
import os
import sys
import argparse
import logging.handlers
from logging.handlers import RotatingFileHandler
import signal
from contextlib import closing
from functools import partial
import traceback
import Queue
import threading
import json
from operator import not_

import psycopg2.extensions

# pylint: disable-msg=E0611
from minerva.util import each, iter_queue, make_tuple, compose, \
    no_op, after, retry_while
from minerva.util.config import parse_size, load_config, get_defaults, \
    ConfigError
from minerva.db.util import stored_procedure
from minerva.system.jobqueue import enqueue_job
from minerva.instance import MinervaInstance

from minerva_dispatcher import __version__ as version, setup_notifier, \
    JOB_TYPE, get_job_sources

TIMEOUT = 1.0

SIGNAL_MAP = {
    signal.SIGKILL: "SIGKILL",
    signal.SIGTERM: "SIGTERM",
    signal.SIGINT: "SIGINT",
    signal.SIGUSR1: "SIGUSR1"
}

package_name = "minerva_dispatcher"
script_name = os.path.basename(__file__)
config_file = "{}.conf".format(script_name)


def main():
    """
    Script entry point
    """
    default_minerva_instance = os.environ.get("DEFAULT_MINERVA_INSTANCE",
                                              "default")

    config_file_path = os.path.join("/etc/minerva", config_file)

    parser = argparse.ArgumentParser(
        description="watch job sources for new files/jobs")

    parser.add_argument(
        "--version", action="version", version='%(prog)s {}'.format(version),
        help="display version information and exit")

    parser.add_argument(
        "-i", "--instance", default=default_minerva_instance,
        help="name of the target minerva instance")

    parser.add_argument("-u", "--user", help="user to connect to database")

    parser.add_argument(
        "-c", "--configfile", dest="configfile",
        default=config_file_path, help="the path to the config file")

    parser.add_argument(
        "--generate-configfile", dest="generate_configfile",
        action=GenerateConfigFileAction, nargs=0,
        help="generate base config file")

    args = parser.parse_args()

    minerva_instance = MinervaInstance.load(args.instance)

    try:
        config = load_config(get_defaults(package_name, config_file),
                             args.configfile)
    except ConfigError as exc:
        print("error loading configuration: {}".format(exc))
        return 1

    stop_event = threading.Event()

    stop = after(stop_event.set, log_signal)

    signal.signal(signal.SIGTERM, stop)
    signal.signal(signal.SIGINT, stop)

    try:
        setup_logging(config["log_directory"], config["log_filename"],
                      config["log_rotation_size"], config["log_level"])
    except IOError as exc:
        print(exc)
        return 1

    user = config['database']['user'] or args.user or "minerva_admin"

    def connect():
        while not stop_event.is_set():
            try:
                return minerva_instance.connect(user=user)
            except Exception as exc:
                logging.error(exc)
                stop_event.wait(1.0)

    with closing(connect()) as conn:
        pid = os.getpid()

        queue = Queue.Queue()

        datasource_events = iter_queue(stop_event, queue.get_nowait,
                                       Queue.Empty, TIMEOUT)

        process_datasource_event = partial(process, conn, stop_event)

        consumer_loop = partial(each, process_datasource_event,
                                datasource_events)

        consumer = threading.Thread(target=consumer_loop, name="consumer")
        consumer.start()

        enqueue = compose(queue.put, make_tuple)

        with closing(conn.cursor()) as cursor:
            job_sources = get_job_sources(cursor, JOB_TYPE)

        conn.commit()

        notifier = setup_notifier(job_sources, enqueue)
        notifier.start()

        logging.info("started with pid {0:d}".format(pid))

        while not stop_event.is_set():
            stop_event.wait(1.0)

        notifier.stop()

        conn.commit()

        logging.info("stopped")


def get_script_name():
    directory, filename = os.path.split(__file__)

    return filename


stop_process = partial(stored_procedure, "system.stop_process")


def process(conn, stop_event, item):
    job_source_id, job_description = item

    path = job_description["uri"]

    try:
        filesize = os.path.getsize(path)
    except OSError as exc:
        logging.info("could not get size of file: {}".format(exc))
        return

    e = partial(enqueue_job, conn, JOB_TYPE, json.dumps(job_description),
                filesize, job_source_id)

    # In case of a database shutdown, we first get an InterfaceError and the
    # next time an OperationalError
    exception_handler_map = {
        psycopg2.InterfaceError: no_op,
        psycopg2.OperationalError: no_op}

    condition = compose(not_, stop_event.is_set)

    try:
        retry_while(e, exception_handler_map, condition)
    except Exception:
        logging.error(traceback.format_exc())
        conn.rollback()
    else:
        conn.commit()
        logging.info("enqueued {}".format(path))


def setup_logging(directory, filename, rotation_size, level):
    """
    Setup logging with rotating log files.
    """
    level_map = {
        "DEBUG": logging.DEBUG,
        "INFO": logging.INFO,
        "WARNING": logging.WARNING,
        "ERROR": logging.ERROR,
        "CRITICAL": logging.CRITICAL}

    max_log_size = parse_size(rotation_size)

    filepath = os.path.join(directory, filename)
    handler = RotatingFileHandler(filepath, maxBytes=max_log_size,
                                  backupCount=5)
    handler.setLevel(level_map[level])

    formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    handler.setFormatter(formatter)

    rootlogger = logging.getLogger("")
    rootlogger.setLevel(level_map[level])
    rootlogger.addHandler(handler)


class GenerateConfigFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        sys.stdout.write(get_defaults(package_name, config_file))
        sys.exit(0)


def log_signal(signum, _frame):
    logging.info("Stopping Dispatcher after receiving {0!s} signal".format(
        SIGNAL_MAP.get(signum, signum)))


if __name__ == "__main__":
    main()
