#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Minerva Dispatcher command line script.

Dispatcher/harvest job sources look like this:

{
    "uri": "/data",
    "recursive": true,
    "match_pattern": ".*",
    "job_config": {}
}

"""
__docformat__ = "restructuredtext en"

__copyright__ = """
Copyright (C) 2008, 2013 Hendrikx-ITC B.V.

Distributed under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3, or (at your option) any later
version.  The full license is in the file COPYING, distributed as part of
this software.
"""
import os
import sys
import argparse
import logging.handlers
from logging.handlers import RotatingFileHandler
import signal
from contextlib import closing
from functools import partial
import traceback
import threading
from operator import not_

import psycopg2.extensions

from minerva.util import each, compose, \
    no_op, after, retry_while
from minerva.util.config import parse_size, load_config, get_defaults, \
    ConfigError
from minerva.instance import MinervaInstance

from minerva_dispatcher.version import __version__ as version
from minerva_dispatcher import JobCollector, get_job_sources

SIGNAL_MAP = {
    signal.SIGKILL: "SIGKILL",
    signal.SIGTERM: "SIGTERM",
    signal.SIGINT: "SIGINT",
    signal.SIGUSR1: "SIGUSR1"
}

package_name = "minerva_dispatcher"
script_name = os.path.basename(__file__)
config_file = "{}.conf".format(script_name)


def main():
    """Script entry point."""
    config_file_path = os.path.join("/etc/minerva", config_file)

    parser = argparse.ArgumentParser(
        description="watch job sources for new files/jobs")

    parser.add_argument(
        "--version", action="version", version='%(prog)s {}'.format(version),
        help="display version information and exit")

    parser.add_argument(
        "-i", "--instance",
        help="name of the target minerva instance")

    parser.add_argument("-u", "--user", help="user to connect to database")

    parser.add_argument(
        "-c", "--configfile", dest="configfile",
        default=config_file_path, help="the path to the config file")

    parser.add_argument(
        "--generate-configfile", dest="generate_configfile",
        action=GenerateConfigFileAction, nargs=0,
        help="generate base config file")

    args = parser.parse_args()

    minerva_instance_name = (
        args.instance or
        os.environ.get("MINERVA_INSTANCE") or
        "default"
    )

    minerva_instance = MinervaInstance.load(minerva_instance_name)

    try:
        config = load_config(get_defaults(package_name, config_file),
                             args.configfile)
    except ConfigError as exc:
        print("error loading configuration: {}".format(exc))
        return 1

    stop_event = threading.Event()

    stop = after(stop_event.set, log_signal)

    signal.signal(signal.SIGTERM, stop)
    signal.signal(signal.SIGINT, stop)

    try:
        setup_logging(config["log_directory"], config["log_filename"],
                      config["log_rotation_size"], config["log_level"])
    except IOError as exc:
        print(exc)
        return 1

    user = args.user or config['database']['user'] or "minerva_admin"

    def connect():
        while not stop_event.is_set():
            try:
                return minerva_instance.connect(user=user)
            except Exception as exc:
                logging.error(exc)
                stop_event.wait(1.0)

    with closing(connect()) as conn:
        with closing(conn.cursor()) as cursor:
            job_sources = get_job_sources(cursor)

        conn.commit()

        jobcollector = JobCollector(job_sources, stop_event)
        jobcollector.start()

        process_job = partial(store_job, conn, stop_event)

        consumer_loop = partial(each, process_job,
                                jobcollector.iter_jobs())

        consumer = threading.Thread(target=consumer_loop, name="consumer")
        consumer.start()

        logging.info("started with pid {0:d}".format(os.getpid()))

        while not stop_event.is_set():
            stop_event.wait(1.0)

        jobcollector.stop()

        conn.commit()

        logging.info("stopped")


def store_job(conn, stop_event, job):
    try:
        resilient_db_exec(
            action=partial(job.enqueue, conn),
            stop_event=stop_event)
    except:
        logging.error(traceback.format_exc())
        conn.rollback()
    else:
        conn.commit()
        logging.info("enqueued {}".format(job.description["uri"]))


# In case of a database shutdown, we first get an InterfaceError and the
# next time an OperationalError
EXCEPTION_HANDLER_MAP = {
    psycopg2.InterfaceError: no_op,
    psycopg2.OperationalError: no_op}


def resilient_db_exec(action, stop_event):
    condition = compose(not_, stop_event.is_set)

    retry_while(action, EXCEPTION_HANDLER_MAP, condition)


def setup_logging(directory, filename, rotation_size, level):
    """Setup logging with rotating log files."""
    level_map = {
        "DEBUG": logging.DEBUG,
        "INFO": logging.INFO,
        "WARNING": logging.WARNING,
        "ERROR": logging.ERROR,
        "CRITICAL": logging.CRITICAL}

    max_log_size = parse_size(rotation_size)

    filepath = os.path.join(directory, filename)
    handler = RotatingFileHandler(filepath, maxBytes=max_log_size,
                                  backupCount=5)
    handler.setLevel(level_map[level])

    formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    handler.setFormatter(formatter)

    rootlogger = logging.getLogger("")
    rootlogger.setLevel(level_map[level])
    rootlogger.addHandler(handler)


class GenerateConfigFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        sys.stdout.write(get_defaults(package_name, config_file))
        sys.exit(0)


def log_signal(signum, _frame):
    logging.info("Stopping Dispatcher after receiving {0!s} signal".format(
        SIGNAL_MAP.get(signum, signum)))


if __name__ == "__main__":
    main()
