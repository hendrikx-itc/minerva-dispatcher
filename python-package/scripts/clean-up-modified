#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script for deleting unmonitored and old records from trend.modified
"""
import os
import sys
import argparse
import logging
from contextlib import closing
from logging.handlers import RotatingFileHandler
from datetime import datetime
from functools import partial
import re
import pytz

from configobj import ConfigObj

from minerva.db import connect
from minerva.util import parse_size
from minerva.util.config import get_config

from minerva.transform.helpers import get_all_function_sets


DEFAULT_CONFIG = """\
db_uri = postgresql://<user>:<password>@<host>/<minerva_database>
timezone = Europe/Amsterdam
log_directory = /var/log/minerva/
log_filename = clean-up-modified.log
log_rotation_size = 10MB
log_level = INFO"""


def main():
    parser = argparse.ArgumentParser(
            description="Compile backlog based on trend.modified table")

    parser.add_argument("-c", "--configfile",
            default="/etc/minerva/clean-up-modified.conf", help="path to config file")

    parser.add_argument("--generate-configfile",
            action=GenerateConfigFileAction, nargs=0, help="generate default config file")

    parser.add_argument("--verbose", action="store_true", default=False)

    args = parser.parse_args()

    config = get_config(DEFAULT_CONFIG, args.configfile)

    setup_logging(args.verbose)
    setup_file_logging(config["log_directory"], config["log_filename"],
        config["log_rotation_size"], config["log_level"])

    connect_to_db = partial(connect, config["db_uri"])

    with closing(connect_to_db()) as conn:

        ts = pytz.timezone(config["timezone"]).localize(datetime.now())

        table_names = []
        for function_set in get_all_function_sets(conn):
            table_names.extend(function_set.source_table_names(conn, ts))
            table_names.append(function_set.dest_table_name(conn, ts))

        prefixes = map(get_table_prefix, set(table_names))

        result_prefix = clean_up_by_prefix(conn, prefixes)
        result_obsolete = clean_up_obsolete(conn)

        conn.commit()

        logging.info("Deleted {0} non-monitored and {1} obsolete rows "
            "from trend.modified".format(result_prefix, result_obsolete))

    return 0


def get_table_prefix(table_name):
    """
    Return prefix of trend table name: e.g. 'oss-rc-2g-pm_entitytype_qtr_20121006'
    returns 'oss-rc-2g-pm_entitytype_qtr'
    """
    return re.match("(.*)_\d+$", table_name).groups()[0]


def clean_up_by_prefix(conn, keep_prefixes):
    """
    Delete records from trend.modified but keep records corresponding to
    keep_prefixes
    """
    query = ("DELETE FROM trend.modified "
        "WHERE substring(table_name, '(.*)_\d+$') NOT IN ({0})").format(
            ",".join(["'{}'".format(p) for p in keep_prefixes]))

    with closing(conn.cursor()) as cursor:
        cursor.execute(query)
        return cursor.rowcount

def clean_up_obsolete(conn):
    """
    Delete records from trend.modified that don't correspond to an existing
    table anymore
    """
    query = "DELETE FROM trend.modified "
    "WHERE trend.modified.table_name NOT IN ( "
    "SELECT c.relname "
    "FROM pg_class c "
    "JOIN pg_namespace n ON n.oid = c.relnamespace "
    "WHERE n.nspname = 'trend' and relkind = 'r') "

    with closing(conn.cursor()) as cursor:
        cursor.execute(query)
        return cursor.rowcount


def setup_logging(verbose):
    root_logger = logging.getLogger("")

    if verbose:
        handler = logging.StreamHandler(sys.stdout)
        root_logger.addHandler(handler)

    root_logger.setLevel(logging.INFO)


def setup_file_logging(directory, filename, rotation_size, level):
    """
    Setup rotating file logging.
    """
    level_map = {
        "DEBUG": logging.DEBUG,
        "INFO": logging.INFO,
        "WARNING": logging.WARNING,
        "ERROR": logging.ERROR,
        "CRITICAL": logging.CRITICAL}

    max_log_size = parse_size(rotation_size)

    filepath = os.path.join(directory, filename)
    handler = RotatingFileHandler(filepath, maxBytes=max_log_size, backupCount=5)
    handler.setLevel(level_map[level])

    formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    handler.setFormatter(formatter)

    rootlogger = logging.getLogger("")
    rootlogger.setLevel(level_map[level])
    rootlogger.addHandler(handler)


class GenerateConfigFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        print(DEFAULT_CONFIG)
        sys.exit(0)


if __name__ == "__main__":
    sys.exit(main())
