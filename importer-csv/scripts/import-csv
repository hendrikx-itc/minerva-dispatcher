#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Command line tool for importing CSV files as trend or attribute data.
"""
__docformat__ = "restructuredtext en"

__copyright__ = """
Copyright (C) 2008-2013 Hendrikx-ITC B.V.

Distributed under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3, or (at your option) any later
version.  The full license is in the file COPYING, distributed as part of
this software.
"""
import logging.handlers
import os
import sys
import argparse
from contextlib import closing
from StringIO import StringIO
import json
import re
from functools import partial
import operator

import yaml
from configobj import ConfigObj
from pkg_resources import resource_string

from minerva.instance import MinervaInstance
from minerva.util import identity, compose

from minerva_csvimporter.importer import import_csv, ConfigurationError
from minerva_csvimporter.timestamp_extractor import create_timestamp_fn
from minerva_csvimporter import storage
from minerva_csvimporter.data_requirements import any_field_empty
from minerva_csvimporter.dialects import create_dialect

DEFAULT_CONFIG = resource_string("minerva_csvimporter",
                                 "defaults/import-csv.conf")
DEFAULT_PROFILE = resource_string("minerva_csvimporter", "defaults/profile")

GRANULARITIES = {
    "qtr": 900,
    "hr": 3600,
    "day": 86400,
    "week": 604800}


def main():
    parser = create_argument_parser()

    args = parser.parse_args()

    if args.verbose and args.quiet:
        parser.error("options -v and -q are mutually exclusive")
        return 1

    if args.file_path is None:
        print("Nothing to do: No csv file specified.")
        return 0

    minerva_instance = MinervaInstance.load(args.instance)

    config = get_config(args)

    logging.root.addHandler(logging.StreamHandler())
    logging.root.setLevel(config["log_level"])

    profile = get_profile(config["profile_directory"], args.profile)

    update_profile_from_args(profile, args)

    profile = type_mapping(PROFILE_SCHEMA)(profile)

    _, file_name = os.path.split(args.file_path)

    config_user = config.get("database", {}).get("user")
    user = config_user or args.user or "minerva_admin"

    with closing(minerva_instance.connect(user=user)) as conn:
        logging.info("start processing file {0}".format(args.file_path))
        logging.info("using identifier {0}".format(profile["identifier"]))

        profile["timestamp"].set_filename(file_name)

        with closing(open(args.file_path, "rb")) as csv_file:
            import_csv(conn, profile, args.datasource, csv_file)

        logging.info("finished processing file {0}".format(args.file_path))

    logging.info("Done")

    return 0


def create_argument_parser():
    """
    Return fully configured ArgumentParser
    :rtype : ArgumentParser
    """
    default_minerva_instance = os.environ.get(
        "DEFAULT_MINERVA_INSTANCE", "default")

    parser = argparse.ArgumentParser(
        description="Script for importing csv files")

    parser.add_argument(
        "-i", "--instance", default=default_minerva_instance,
        help="name of the target minerva instance")

    parser.add_argument("datasource", help="name of datasource")

    parser.add_argument(
        "file_path", nargs="?", help="Path of file that will be processed")

    parser.add_argument(
        "--storage-type", default="trend", help="storage type/format to use")

    parser.add_argument(
        "--generate-configfile", action=GenerateConfigFileAction, nargs=0,
        help="generate default config file")

    parser.add_argument(
        "-c", "--configfile", default="/etc/minerva/import-csv.conf",
        help="Path to config file")

    parser.add_argument(
        "--generate-profile-file", action=GenerateProfileFileAction, nargs=0,
        help="generate default profile file")

    parser.add_argument(
        "-p", "--profile", default="default", help="Name of profile")

    parser.add_argument(
        "-v", "--verbose", action="store_true", dest="verbose",
        default=False, help="Produce verbose output")

    parser.add_argument(
        "--ignore-field-mismatches", action="store_true", default=None,
        help="ignore lines with more or less fields than found in header")

    parser.add_argument(
        "-q", "--quiet", action="store_true", dest="quiet", default=False,
        help="produce output to log file")

    parser.add_argument(
        "-g", "--granularity", dest="granularity",
        help="granularity of csv data", choices=GRANULARITIES.keys())

    parser.add_argument("--timezone", help="timezone of data timestamp")

    parser.add_argument("--identifier", help="the identifier column")

    parser.add_argument(
        "--timestamp", help="default timestamp [YYYYmmdd_HHMM | NOW]")

    parser.add_argument(
        "--timestamp-from-filename-regex",
        help="regular expression for timestamp extraction from filename")

    parser.add_argument(
        "--timestamp-format", help="format of date: default: %%Y%%m%%d_%%H%%M")

    parser.add_argument(
        "--timestamp-column", help="column containing timestamps")

    parser.add_argument(
        "--identifier-regex",
        help="Regex for tweaking identifier in identifier field.")

    parser.add_argument(
        "--identifier-is-alias", action="store_true", default=None,
        help="Indicated whether identifier is alias.")

    parser.add_argument(
        "--timestamp-is-start", action="store_true", default=None,
        help="(Timestamp + granularity) will be used as timestamp "
        "in Minerva database.")

    parser.add_argument(
        "--fields", dest="fields", nargs="+",
        help="Fields to import. If not specified all fields are imported.")

    parser.add_argument(
        "--ignore-fields", dest="ignore_fields", nargs="+",
        help="Fields to ignore. If not specified no fields are ignored.")

    parser.add_argument(
        "--character-encoding", dest="character_encoding",
        help="character encoding of the source file")

    parser.add_argument(
        "--dialect", help="CSV dialect", choices=["auto", "prime"])

    parser.add_argument(
        "--value-mapping",
        help="json formatted string for mapping specific values to other "
        "values for specific columns (e.g. {\"ccr\":{\"-1\":\"\"}})")

    return parser


class GenerateConfigFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        sys.stdout.write(DEFAULT_CONFIG)
        sys.exit(0)


class GenerateProfileFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        sys.stdout.write(DEFAULT_PROFILE)
        sys.exit(0)


def get_config(args):
    config = ConfigObj(StringIO(DEFAULT_CONFIG))

    if os.path.isfile(args.configfile):
        custom_config = ConfigObj(args.configfile)
        config.merge(custom_config)

    return config


def assure_type(type, map_to_type=None):
    def fn(value):
        if value is not None:
            if isinstance(value, type):
                return value
            else:
                if map_to_type is not None:
                    return map_to_type(value)
                else:
                    return type(value)

    return fn


def to_granularity_seconds(g):
    return int(GRANULARITIES.get(g, g))


def to_list(l):
    return map(str.strip, ",".split(l))


def to_bool(b):
    return b.lower() in ('t', 'true', '1')


def to_storage(s):
    return storage.type_map[s["type"]](**s["config"])


def select_fields(names):
    def fn(all_names):
        return [name for name in names if name in all_names]

    return fn


def exclude_fields(exclude_names):
    def fn(all_names):
        return [name for name in all_names if not name in exclude_names]

    return fn


def create_field_selector(f):
    type_name = f["type"]

    if type_name == "select":
        return select_fields(f["config"]["names"])

    elif type_name == "exclude":
        return exclude_fields(f["config"]["names"])

    elif type_name == "all":
        return identity

    else:
        raise Exception("No such field selector: {}".format(type_name))


class IdentifierExtractor(object):
    def __init__(self, template, regex):
        self.template = template
        self.regex = regex

        self.fields = re.findall(r"{(\w+)}", template) or [template]

        if self.fields:
            #composed identifier (e.g. '{fld1}-{fld2}, {fld1}:{fld2}')
            get_identifier = expand_kwargs(template.format)
        else:
            get_identifier = partial(get_value_by_key, identifier)

        extract_ident = partial(extract_identifier, regex)

        self.record_to_dn = compose(extract_ident, get_identifier)

    def __str__(self):
        return self.template

    def get_dn_from_record(self, record):
        return self.record_to_dn(record)

    def header_requirements(self):
        return []

    def record_requirements(self):
        return [
            compose(operator.not_, any_field_empty(self.fields))
        ]


def extract_identifier(pattern, value):
    regex = re.compile(pattern)

    m = regex.match(value)

    return "".join(m.groups())


def expand_kwargs(fn):
    def expander(kwargs):
        return fn(**kwargs)

    return expander


PROFILE_SCHEMA = {
    "storage": assure_type(storage.Storage, to_storage),
    "field_selector": create_field_selector,
    "timezone": str,
    "ignore_field_mismatches": assure_type(bool, to_bool),
    "identifier": expand_kwargs(IdentifierExtractor),
    "timestamp": create_timestamp_fn,
    "character_encoding": str,
    "dialect": create_dialect,
    "value_mapping": assure_type(dict, json.loads)
}


def update_profile_from_args(profile, args):
    if args.identifier:
        profile["identifier"]["template"] = args.identifier

    if args.identifier_regex:
        profile["identifier"]["regex"] = args.identifier_regex

    if args.character_encoding:
        profile["character_encoding"] = args.character_encoding


def load_profile(profile_directory, name):
    possible_profile_paths = [
        name,
        os.path.join(profile_directory, name)
    ]

    try:
        profile_path = next(
            path for path in possible_profile_paths if os.path.isfile(path)
        )
    except StopIteration:
        raise ConfigurationError("profile '{}' not found".format(name))
    else:
        return yaml.load(open(profile_path))


def get_profile(profile_directory, profile_name):
    profile = yaml.load(StringIO(DEFAULT_PROFILE))

    try:
        profile.update(
            load_profile(profile_directory, profile_name)
        )
    except ConfigurationError as exc:
        logging.warn("{} - using defaults".format(exc))

    return profile


def type_mapping(schema):
    def fn(data):
        return {k: schema.get(k)(v) for k, v in data.iteritems()}

    return fn


if __name__ == '__main__':
    sys.exit(main())
